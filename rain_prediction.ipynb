{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73ddd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (145460, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from your data folder\n",
    "df = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "\n",
    "# Check basic shape\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928f4094",
   "metadata": {},
   "source": [
    "#### Step 1: Check for Missing Values\n",
    "\n",
    "Understanding which columns have missing data helps determine what should be cleaned or dropped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103d31f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "WindDir9am       10566\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "Humidity3pm       4507\n",
       "WindDir3pm        4228\n",
       "Temp3pm           3609\n",
       "RainTomorrow      3267\n",
       "Rainfall          3261\n",
       "RainToday         3261\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Temp9am           1767\n",
       "WindSpeed9am      1767\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many missing values per column\n",
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "missing[missing > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c020a",
   "metadata": {},
   "source": [
    "#### Step 2: Drop Columns with Excessive Missing Data\n",
    "\n",
    "The following features have more than 40% missing data and would reduce the dataset size significantly if we tried to impute them. Therefore, we remove them:\n",
    "- Sunshine (69,835 missing)\n",
    "- Evaporation (62,790)\n",
    "- Cloud3pm (59,358)\n",
    "- Cloud9am (55,888)\n",
    "\n",
    "These features are dropped to maintain data quality and avoid introducing noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc7741d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of high-missing columns we want to drop\n",
    "to_drop = ['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']\n",
    "\n",
    "# Drop only the ones that exist\n",
    "df.drop(columns=[col for col in to_drop if col in df.columns], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cfa263",
   "metadata": {},
   "source": [
    "#### Step 3: Drop Rows with Missing Target\n",
    "\n",
    "Rows missing the target variable (`RainTomorrow`) cannot be used for training or evaluation and are removed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85437892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['RainTomorrow'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99600e7",
   "metadata": {},
   "source": [
    "#### Step 4: Fill Remaining Missing Values\n",
    "\n",
    "Numerical columns are filled with their mean, and categorical columns with their most frequent value (mode).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbcb808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numerical columns\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].mean())\n",
    "\n",
    "# Fill categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e62ea",
   "metadata": {},
   "source": [
    "#### Step 5: Encode Categorical Variables\n",
    "\n",
    "The target and binary features are converted to 1s and 0s. All other categorical features are one-hot encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e826708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainTomorrow'] = df['RainTomorrow'].map({'Yes': 1, 'No': 0})\n",
    "df['RainToday'] = df['RainToday'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# One-hot encode remaining categorical variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24341f",
   "metadata": {},
   "source": [
    "#### Step 6: Split Features and Target\n",
    "\n",
    "Now that the dataset is clean and encoded, we separate the features (X) from the target variable (y).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1900a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('RainTomorrow', axis=1)\n",
    "y = df['RainTomorrow']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c80686",
   "metadata": {},
   "source": [
    "#### Step 7: Train/Test Split\n",
    "\n",
    "Split the data into training and testing sets to evaluate performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82ea67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b54a26c",
   "metadata": {},
   "source": [
    "## 2. Modelling / Classification\n",
    "\n",
    "In this section, we apply several supervised machine learning algorithms to classify whether it will rain tomorrow. The models are trained on the preprocessed data and evaluated using accuracy, confusion matrix, and classification reports. Three different classifiers are compared to assess performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ef23a",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression\n",
    "\n",
    "Logistic Regression is a simple and interpretable linear model for binary classification. It models the probability of a binary response based on one or more predictor variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b236b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8455993530011604\n",
      "\n",
      "Confusion Matrix:\n",
      " [[20962  1102]\n",
      " [ 3289  3086]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91     22064\n",
      "           1       0.74      0.48      0.58      6375\n",
      "\n",
      "    accuracy                           0.85     28439\n",
      "   macro avg       0.80      0.72      0.74     28439\n",
      "weighted avg       0.84      0.85      0.83     28439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=5000, solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185122c",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest\n",
    "\n",
    "Random Forest is an ensemble method that builds multiple decision trees and merges them to get a more accurate and stable prediction. It works well on structured/tabular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "196611f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7900066809662787\n",
      "\n",
      "Confusion Matrix:\n",
      " [[22030    34]\n",
      " [ 5938   437]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88     22064\n",
      "           1       0.93      0.07      0.13      6375\n",
      "\n",
      "    accuracy                           0.79     28439\n",
      "   macro avg       0.86      0.53      0.50     28439\n",
      "weighted avg       0.82      0.79      0.71     28439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Reduce number of trees to speed things up\n",
    "rf_model = RandomForestClassifier(n_estimators=30, max_depth=15, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c5e27",
   "metadata": {},
   "source": [
    "### 2.3 Support Vector Machine (SVM)\n",
    "\n",
    "SVM aims to find a hyperplane that best separates the classes in the data. It is effective in high-dimensional spaces but can be slow on large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
